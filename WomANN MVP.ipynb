{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8041183a",
   "metadata": {},
   "source": [
    "# Developing a Women's Health Minimum Viable Product with the Assistance of ChatGPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f35712e",
   "metadata": {},
   "source": [
    "#### By Emmitt Tucker "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e055a4f",
   "metadata": {},
   "source": [
    "Youtube Video Link: https://youtu.be/o-1LOEEcZbg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13494464",
   "metadata": {},
   "source": [
    "## Abstract "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44620ff",
   "metadata": {},
   "source": [
    "This paper explores the development of the Women's Advancement Neural Network (Wom.A.N.N.) MVP - a revolutionary tool aimed at aiding research into women's health issues, and facilitating women's active participation in this research. With women's health concerns being significantly underrepresented in clinical studies and medical research, this tool is designed to bridge the gap by encouraging and empowering women to share their health experiences in a secure and anonymous platform.<br>\n",
    "<br>\n",
    "Innovatively, the development and ideation of the Wom.A.N.N. MVP were facilitated using the assistance of a language model AI, ChatGPT. The project utilized an interactive AI-centric process, demonstrating the power and utility of AI as a development tool, especially for individuals with limited coding experience. The system collects self-reported health data through a series of user-friendly surveys and stores this data in a structured and usable format.<br>\n",
    "<br>\n",
    "Furthermore, this paper outlines the methods and techniques used to create the MVP and details how ChatGPT was directed through a series of engineered prompts to produce the desired code. The successful implementation of the MVP demonstrated the potential of AI in rapidly prototyping a product with quick turnaround times, even with minimal coding expertise.<br>\n",
    "<br>\n",
    "The ultimate goal of the Wom.A.N.N. is to train an Artificial Neural Network with the collected data to predict the level of depression in users, thereby providing potentially life-saving resources and interventions. Future work includes the integration of blockchain technology for enhanced security, and the development of more personalized, human-in-the-loop features.<br>\n",
    "<br>\n",
    "In essence, this paper serves as both a blueprint for using AI as a development tool and a step forward in the advancement of women's health research and resources. This unique combination of AI and active participation from users sets a new standard for health-based applications and provides a promising glimpse into the future of women's healthcare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7345c1",
   "metadata": {},
   "source": [
    "## Introduction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203269c",
   "metadata": {},
   "source": [
    "### The problem "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1e885d",
   "metadata": {},
   "source": [
    "Women's health is a critical area of medical science, yet it is often under-researched and overlooked. Various social, cultural, and logistical barriers often hinder women's health research, leading to a significant lack of data and an incomplete understanding of women's health issues. This gap in knowledge ultimately results in suboptimal treatment strategies, diagnoses, and overall care for women.<br>\n",
    "<br>\n",
    "One of the core issues is the societal stigma and embarrassment associated with discussing certain health issues, particularly those related to sexual or reproductive health. This can discourage women from seeking help or participating in studies, leading to underreporting and lack of data. These societal taboos can often make it challenging for women to feel comfortable discussing their health, even with healthcare professionals. This phenomenon is not limited to any specific region or culture; it's seen worldwide and can lead to severe health conditions going undiagnosed or untreated until it's too late.<br>\n",
    "<br>\n",
    "Furthermore, traditional research methods can be invasive and time-consuming, deterring women from participating. Coupled with the often male-dominated research sphere, which may not fully understand or take into account the unique health experiences of women, it can lead to lower participation in research studies. <br>\n",
    "<br>\n",
    "Additionally, research in women's health often lacks sufficient diversity. Studies historically have tended to focus on white, middle-class women, neglecting women of color, women from lower socioeconomic backgrounds, and women from various cultural backgrounds. This lack of inclusivity reduces the generalizability of research findings and exacerbates health disparities.<br>\n",
    "<br>\n",
    "Lastly, research often fails to take into account the full breadth of women's health, focusing primarily on reproductive health and neglecting areas like mental health, chronic disease, and the effects of aging. This approach oversimplifies women's health, overlooking its complexity and the interplay of various physiological, mental, and social factors.<br>\n",
    "<br>\n",
    "Altogether, these issues create a significant challenge for women's health research, with serious implications for the health and wellbeing of women worldwide. It's clear that a solution is urgently needed - one that addresses these barriers and opens new avenues for gathering data and enhancing our understanding of women's health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a90510",
   "metadata": {},
   "source": [
    "### The Solution "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c297a6a2",
   "metadata": {},
   "source": [
    "The solution proposed is a unique blend of human and AI interaction, termed as \"Human in the Loop AI\". This interaction model ensures that while AI is at the heart of the operation, it is supported, guided, and influenced by human judgment and participation at key intervals. In this case, the initiative is centered around the participation of women worldwide through an easy-to-use app, engaging them in a crowdsourced research platform to foster women's health research.<br>\n",
    "<br>\n",
    "The central idea is to harness the capabilities of AI to structure and interpret vast amounts of data collected via the app. This data collection occurs through a survey modeled to be as accessible and comfortable as possible, relying on simple 'yes' or 'no' responses to gather data about various aspects of women's health. It's designed to respect user comfort levels and allow them to control the depth of their responses.<br>\n",
    "<br>\n",
    "By integrating the AI with blockchain technology, the solution ensures the security and integrity of the data gathered. Each data point can be verified and traced, ensuring data credibility for research purposes while simultaneously maintaining user anonymity.<br>\n",
    "<br>\n",
    "The applicationâ€™s first phase will involve gathering preliminary data, which will be utilized to train the AI and provide a 'soft' interpretation of health metrics. The participants can then review these interpretations, which would help adjust and train the AI further. Over time, this process will result in an AI that is progressively more effective in interpreting the data.<br>\n",
    "<br>\n",
    "However, the role of human intervention does not cease here. User feedback continues to play a critical role throughout the different phases of the application. Each woman using the app will be able to evaluate the AI's performance, providing essential feedback that will help refine and improve the system continually. Thus, the system depends heavily on the human users' interaction to perfect the AI.<br>\n",
    "<br>\n",
    "Ultimately, the Human in the Loop model ensures a balance between the precision and processing power of AI and the nuanced judgment and real-world context that human users provide. Through this method, the project hopes to generate a vast dataset of women's health metrics, which can be utilized in various health research, thereby filling the current data gap in women's health and advancing the field significantly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a3936",
   "metadata": {},
   "source": [
    "## Objective/Purpose "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a57d61",
   "metadata": {},
   "source": [
    "The fundamental objective of this project is two-fold: developing a minimum viable product (MVP) for data collection and promoting an innovative approach towards software development.<br>\n",
    "<br>\n",
    "Primarily, the project aims to construct an MVP that enables effective and extensive data collection on women's health. The MVP, an easy-to-use mobile app, aims to break down the barriers that currently hinder data collection in the field of women's health. It operates based on the principle of crowdsourcing, thereby encouraging the participation of a diverse range of women, making it more inclusive and comprehensive. By doing so, it helps gather rich, diverse, and real-world data, which forms a solid foundation for further research and understanding.<br>\n",
    "<br>\n",
    "The data collected through the MVP will be instrumental in training an AI model specifically designed to interpret women's health metrics. Over time, as more data is collected and the AI model is continuously trained and refined, the project aims to provide valuable insights into women's health and enable women to gain a deeper understanding of their health status. This goal not only solves the immediate issue of the lack of data but also has significant potential to revolutionize the field of women's health research.<br>\n",
    "<br>\n",
    "Simultaneously, the project carries a secondary objective â€“ encouraging non-professionals to venture into software development. By employing 'prompt engineering' and leveraging the capabilities of ChatGPT, an advanced language model developed by OpenAI, the project illustrates that complex software solutions can be developed without traditional coding knowledge. <br>\n",
    "<br>\n",
    "This innovative approach democratizes the field of software development, making it accessible to a larger population, regardless of their professional background or coding expertise. It thereby encourages creativity, problem-solving, and the development of unique solutions, potentially leading to a multitude of novel projects that can help address various societal issues.<br>\n",
    "<br>\n",
    "In essence, the purpose of this project transcends the conventional boundaries, aiming to make a significant impact not only in the field of women's health research but also in the realm of software development and problem-solving at large. By doing so, it hopes to encourage broader participation, foster innovation, and ultimately contribute to a better understanding of women's health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043976a9",
   "metadata": {},
   "source": [
    "## Methods "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec071ccc",
   "metadata": {},
   "source": [
    "The methods utilized in this project were a unique blend of inspiration, ideation, advanced language model utilization, and prompt re-engineering, alongside strategic data design for machine learning algorithms.<br>\n",
    "<br>\n",
    "The genesis of the idea can be traced back to my relationship with an ObGyn. Being close to a healthcare professional provided firsthand exposure to the myriad challenges in the women's health domain. This exposure sparked the initial thought process, leading to the conceptualization of a unique solution â€“ a mobile application designed to collect women's health data anonymously, leveraging the power of AI.<br>\n",
    "<br>\n",
    "The development process involved the creative use of 'prompt engineering' with ChatGPT, OpenAI's state-of-the-art language model. This tool, designed to understand and generate human-like text, played a pivotal role in the development of the MVP without using traditional coding. The goal was to utilize ChatGPT to its maximum potential, using its ability to understand the context of our objectives and generate the necessary code.<br>\n",
    "<br>\n",
    "However, it's worth noting that this process was not without its challenges. At times, it was necessary to re-engineer the prompts to steer ChatGPT in the right direction, as it occasionally failed to comprehend the context of the objectives correctly. This iterative, trial-and-error approach required persistence, creativity, and a thorough understanding of how language models work. Despite these challenges, the approach ultimately proved effective, resulting in a functional MVP.<br>\n",
    "<br>\n",
    "Equally crucial to the project was the design of the dataframe. To ensure compatibility with machine learning algorithms, the dataframe was meticulously structured. Each question and its corresponding response were set as unique variables, thus allowing the algorithm to process the data efficiently. Moreover, the addition of conditional follow-up questions in the code further enriched the data, providing more nuanced insights into each participant's health.<br>\n",
    "<br>\n",
    "The collected data from the MVP formed the backbone of the AI model. A neural network was designed, capable of analyzing and interpreting the gathered data. However, due to slight discrepancies in variable names, modifications are required to ensure smooth processing of the data. <br>\n",
    "<br>\n",
    "Lastly, it's noteworthy to mention that the entire research was conducted in record time, demonstrating the efficiency and potential of this methodology.<br>\n",
    "<br>\n",
    "In sum, this project was an exploratory journey into the realm of AI and machine learning, leading to the creation of a tangible product that holds significant promise for the advancement of women's health research. The methods adopted have showcased a new approach to software development, underlining the potential of AI language models and strategic data design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5aba1c2",
   "metadata": {},
   "source": [
    "## Results and Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dfc7c9",
   "metadata": {},
   "source": [
    "The result of our efforts in this project was the successful creation of a minimum viable product (MVP) for the Women's Advancement Neural Network (Wom.A.N.N.) - a revolutionary tool aimed at contributing to women's health research and fostering women's physical and mental wellbeing. In the course of this project, we leveraged the capabilities of OpenAI's ChatGPT to build a functional prototype with remarkable speed, despite having limited prior experience in coding. This highlights the immense potential of AI-powered tools in simplifying and accelerating the software development process.<br>\n",
    "<br>\n",
    "However, the journey was not without its challenges. One of the primary difficulties encountered was in communicating our exact requirements to the large language model, ChatGPT. There were instances where the model could not fully grasp the context or the objective of a certain request, leading to outputs that were not in alignment with our expectations. This necessitated a degree of trial-and-error and prompted us to engage in prompt engineering â€“ crafting our queries in a way that would elicit the most accurate and helpful response from the AI.<br>\n",
    "<br>\n",
    "While initially, this might seem like a limitation, we perceived it as an opportunity for learning. The process allowed us to understand better the intricacies of interacting with AI and fine-tuning our communication to achieve the desired output. Over time, as we iterated and refined our prompts, we noticed substantial improvements in the accuracy and relevance of the AI's responses. This not only expedited our development process but also enhanced the functionality and robustness of our MVP.<br>\n",
    "<br>\n",
    "In retrospect, while the development of Wom.A.N.N. MVP served as a testament to the efficacy of AI in rapid prototyping, it also shed light on the importance of clear and contextual communication with AI systems. Our experience demonstrates that while AI has tremendous potential to assist in software development, realizing this potential requires a good understanding of how to effectively interact with these systems.<br>\n",
    "<br>\n",
    "Moreover, the creation of this MVP serves as an encouraging example for individuals or groups who may not have extensive coding experience but wish to create a functional software prototype. With tools like ChatGPT, it's becoming increasingly feasible to quickly develop prototypes and bring ideas to life, all while learning valuable skills in AI interaction.<br>\n",
    "<br>\n",
    "The use of AI to develop the Wom.A.N.N. MVP was also significant in highlighting how AI can contribute to sectors beyond software development. In this case, it provided an accessible and anonymous platform for women to participate in health research, thus addressing critical gaps in women's health data.The results of our efforts underscore the potential of AI-powered tools to simplify software development, enhance the rapidity of prototyping, and contribute to important social causes, despite the challenges that may arise in the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c35a841",
   "metadata": {},
   "source": [
    "## Model Building and Training Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a194a17",
   "metadata": {},
   "source": [
    "For this project, we've identified several crucial steps and methods for effectively building, training, and maintaining our machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9fc00c",
   "metadata": {},
   "source": [
    "### Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5afb80f0",
   "metadata": {},
   "source": [
    "In our project, Wom.A.N.N., feature engineering is utilized to maximize the efficacy of the neural network model. The process involves the transformation of raw survey data into a form more amenable to machine learning. The data acquired includes categorical variables (Yes/No responses) and numerical variables (age, weight, height). To enhance the model's performance, feature selection techniques are applied to pinpoint the most influential predictors. This enhances model interpretability, reduces the risk of overfitting, and optimizes model performance. Feature engineering is a crucial part of the Wom.A.N.N. model building process, significantly shaping the effectiveness and efficiency of the overall system."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db1280a",
   "metadata": {},
   "source": [
    "### Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7113a664",
   "metadata": {},
   "source": [
    "Before we can begin building the model, we must first pre-process our collected data. Categorical variables, such as the yes or no responses from the survey, should be encoded into a format that the model can understand. One-hot encoding is a common method used for this purpose. Numerical variables, such as age and weight, should be scaled to ensure they all fall within a similar range. Standardization or normalization are techniques that can be employed for this purpose. This will help ensure that no single feature dominates the model due to its scale."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0eb49e6",
   "metadata": {},
   "source": [
    "### Model Selection "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b66374",
   "metadata": {},
   "source": [
    "Given the complexity and high-dimensionality of our data, a neural network model is a good choice for our machine learning algorithm. Neural networks are particularly adept at handling large datasets and capturing complex relationships among features. Furthermore, they offer strong predictive capabilities which will be critical for achieving our objective of predicting depression levels among our users."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f06da1e",
   "metadata": {},
   "source": [
    "### Hyperparameter Optimization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acebd57e",
   "metadata": {},
   "source": [
    "Once our model has been selected, the next step is hyperparameter optimization. This is a critical step that can significantly impact the performance of our model. Techniques such as grid search and random search can be used to identify the optimal hyperparameters for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51fc4e",
   "metadata": {},
   "source": [
    "### Explainability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd5d39",
   "metadata": {},
   "source": [
    "Despite the black box nature of many machine learning models, it's crucial for our application to have explainable elements. The user should be able to understand, at least to a certain extent, how and why certain predictions were made. Techniques such as LIME (Local Interpretable Model-agnostic Explanations) or SHAP (SHapley Additive exPlanations) can be used to provide some interpretability to our model's predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878558ca",
   "metadata": {},
   "source": [
    "### Human-in-the-loop "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c69ef1cb",
   "metadata": {},
   "source": [
    "Our model should be designed to accommodate regular retraining, allowing us to incorporate fresh data and keep our predictions as accurate as possible. This is where the concept of human-in-the-loop comes into play. By continuously evaluating the model's performance and providing feedback, we can ensure that the model stays up-to-date with the most recent data and trends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1407d4cb",
   "metadata": {},
   "source": [
    "### Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a973a58",
   "metadata": {},
   "source": [
    "For fostering a sense of community among our users, a clustering algorithm could be implemented. This would group women with similar health profiles, thereby enabling users to connect and share experiences with others who are undergoing similar health issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0752068a",
   "metadata": {},
   "source": [
    "### Other Algorithms "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a0be52",
   "metadata": {},
   "source": [
    "Apart from neural networks, other machine learning models might also be suitable, depending on the specific task at hand. For instance, Random Forests or Gradient Boosting machines could be employed for their robustness and ability to handle a variety of data types. Support Vector Machines might be used for their excellent performance in high-dimensional spaces. For sequence data, Recurrent Neural Networks or Transformers could be considered. <br>\n",
    "<br>\n",
    "Remember, the choice of the model heavily depends on the data at hand and the specific objective we're trying to achieve. Each of these models has its strengths and weaknesses, and it is through careful consideration of these factors that we can make the best model choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c399899",
   "metadata": {},
   "source": [
    "## Privacy and Ethics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f2b6c9",
   "metadata": {},
   "source": [
    "Privacy and ethical handling of sensitive information are paramount in health-related data collection and research. The Women's Advancement Neural Network (Wom.A.N.N) project places a high value on these principles, implementing robust measures to protect participant data and uphold ethical standards.<br>\n",
    "<br>\n",
    "One of the primary techniques used to secure the data collected is the integration of blockchain technology. Blockchain, a decentralized and immutable ledger system, ensures the security and integrity of health data by preventing unauthorized access and tampering. Each record (block) in the dataset is linked to the previous record through cryptographic hashes, making it near impossible to alter past records without breaking the chain. This technology guarantees the data's authenticity and safeguards it from potential breaches or malicious activities.<br>\n",
    "<br>\n",
    "Furthermore, the app collects data anonymously, ensuring individual participants cannot be identified. This anonymity is maintained even when datasets are provided to third-party researchers or institutions. In fact, stringent criteria have been established to regulate access to the data collected. The project is committed to only partnering with organizations that uphold the same ethical standards and whose aim aligns with the goal of advancing women's health research. Data will not be sold to purely profit-driven companies, ensuring it is used solely for the purpose of contributing to scientific knowledge and improving women's health outcomes.<br>\n",
    "<br>\n",
    "Lastly, the project remains transparent about its data collection and usage policies. Before participating, users are fully informed about the nature of data being collected, its intended use, and the measures taken to protect it. This open communication ensures participants provide informed consent, respecting their autonomy and reinforcing the ethical foundation of the Wom.A.N.N project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96db48a",
   "metadata": {},
   "source": [
    "## Conclusion and Future Work "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f46d43",
   "metadata": {},
   "source": [
    "In conclusion, we successfully created a minimal viable product (MVP) that allows women to participate in anonymous health research by answering questions related to their physical and mental well-being. This product, named \"Women's Advancement Neural Network (Wom.A.N.N.)\", is built using the power of AI and with the aim of improving women's health.<br>\n",
    "<br>\n",
    "The development of this MVP highlights the potential for technology and AI to bridge gaps in health research and healthcare services. This approach not only has the potential to ameliorate data scarcity in women's health but also to empower women in understanding and maintaining their health. It also opens the door for women to engage in dialogue about health issues that they may otherwise feel uncomfortable discussing.<br>\n",
    "<br>\n",
    "However, this is only the beginning of the journey. There are several enhancements that we envision for the future, aimed at increasing the utility of Wom.A.N.N and making it more user-friendly. <br>\n",
    "<br>\n",
    "First, we plan to personalize the questionnaire. The questions posed to the users will be adapted based on their name and the level of intimacy they're comfortable with. We believe that this will lead to more genuine and complete responses, thereby improving the quality of our dataset. <br>\n",
    "<br>\n",
    "Second, we plan to incorporate blockchain technology into the application. This will provide an additional layer of security, ensuring the anonymity and confidentiality of our users' data. It will also enable the creation of a tamper-proof, decentralized database of women's health, accessible for research under proper ethical guidelines.<br>\n",
    "<br>\n",
    "Third, we aim to enhance the application interface to resemble popular applications like Tinder, making it more engaging and easier to use. We believe that familiarity will enhance user experience and thus, participation.<br>\n",
    "<br>\n",
    "Fourth, we would like to add feature engineering to the dataset. This would involve using survey answers to generate new variables that may increase the accuracy of the machine learning modesl built with the resulting data generating from this application. <br>\n",
    "<br>\n",
    "A significant addition to Wom.A.N.N will be the inclusion of a 'human-in-the-loop' mechanism. This will involve real-time feedback and interaction with users, ensuring that the AI is continually learning and improving from human inputs. <br>\n",
    "<br>\n",
    "Lastly, but most importantly, we envision Wom.A.N.N as a platform where women can connect and talk about their health issues, all the while maintaining their anonymity. It is expected that this feature would reduce the stigma around discussing certain health issues and foster a sense of community among users.<br>\n",
    "<br>\n",
    "In the upcoming stages of this project, we will focus on making these additions to our application, along with refining our AI model as more data becomes available. As we continue to expand and enhance W.A.N.N, we look forward to it becoming a vital tool in women's health research and a trusted companion for women in their journey towards better health."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c29c1b7f",
   "metadata": {},
   "source": [
    "## The Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b963bd",
   "metadata": {},
   "source": [
    "### Basic Tkinter Window Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89d90ae",
   "metadata": {},
   "source": [
    "This was the first check point in the MVP creation process. I was able to use ChatGPT to effectively create a tkinter window that contained the questions I wanted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a080491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "\n",
    "# Defining the Health Questions\n",
    "\n",
    "health_questions = [\n",
    "    \"Have you had any headaches in the past week?\",\n",
    "    \"Have you been exercising regularly?\",\n",
    "    \"Are you currently on any form of medication?\",\n",
    "    # Add more questions as needed.\n",
    "]\n",
    "\n",
    "current_question = 0\n",
    "\n",
    "responses = {}\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question\n",
    "    responses[health_questions[current_question]] = response\n",
    "    current_question += 1\n",
    "    if current_question < len(health_questions):\n",
    "        question.config(text=health_questions[current_question])\n",
    "    else:\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        root.quit()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "question = tk.Label(root, text=health_questions[current_question])\n",
    "question.pack()\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"))\n",
    "yes_button.pack()\n",
    "\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"))\n",
    "no_button.pack()\n",
    "\n",
    "root.mainloop()\n",
    "\n",
    "print(responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5655a75",
   "metadata": {},
   "source": [
    "### Adding ChatGPTs Button Recommedations and Saving answers to a dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e34b9",
   "metadata": {},
   "source": [
    "ChatGPT had recommended me buttons to include in order to flesh out the UI of the MVP. I asked it to update the code with the recommendations. This was the resulting code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd702ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "\n",
    "health_questions = [\n",
    "    \"Have you had any headaches in the past week?\",\n",
    "    \"Have you been exercising regularly?\",\n",
    "    \"Are you currently on any form of medication?\",\n",
    "    # Add more questions as needed.\n",
    "]\n",
    "\n",
    "current_question = 0\n",
    "responses = pd.DataFrame(columns=[\"Question\", \"Answer\"])\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question\n",
    "    global responses\n",
    "    responses = responses.append({\"Question\": health_questions[current_question], \"Answer\": response}, ignore_index=True)\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "def update_question():\n",
    "    if current_question < len(health_questions):\n",
    "        question.config(text=f\"{current_question + 1}. {health_questions[current_question]}\")\n",
    "    else:\n",
    "        responses.to_csv(\"responses.csv\", index=False)\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        def update_question():\n",
    "            if current_question < len(health_questions):\n",
    "                question.config(text=f\"{current_question + 1}. {health_questions[current_question]}\")\n",
    "            else:\n",
    "                responses.to_csv(\"responses.csv\", index=False)\n",
    "                messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "                root.destroy()  # Close the window and return from mainloop\n",
    "\n",
    "\n",
    "def go_back():\n",
    "    global current_question\n",
    "    if current_question > 0:\n",
    "        current_question -= 1\n",
    "        responses.drop(responses.tail(1).index, inplace=True)  # Removes last answer\n",
    "        update_question()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "question = tk.Label(root, text=f\"{current_question + 1}. {health_questions[current_question]}\")\n",
    "question.pack()\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"))\n",
    "yes_button.pack()\n",
    "\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"))\n",
    "no_button.pack()\n",
    "\n",
    "back_button = tk.Button(root, text=\"Back\", command=go_back)\n",
    "back_button.pack()\n",
    "\n",
    "skip_button = tk.Button(root, text=\"Skip\", command=lambda: record_response(\"skip\"))\n",
    "skip_button.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45eac59",
   "metadata": {},
   "source": [
    "### Changing the CSV layout and having the user enter their name. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fa3b5e",
   "metadata": {},
   "source": [
    "I then needed to change the csv layout so that it would be able to be processed by a maching learning algorithm. I also made it so the user would be prompted to enter their name at the beginning of the survey to log their information to on particular individaul. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8533d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "health_questions = [\n",
    "    \"Have you had any headaches in the past week?\",\n",
    "    \"Have you been exercising regularly?\",\n",
    "    \"Are you currently on any form of medication?\",\n",
    "    # Add more questions as needed.\n",
    "]\n",
    "\n",
    "current_question = -1\n",
    "responses = {}\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question\n",
    "    if current_question >= 0:  # Skip if still on name entry stage\n",
    "        responses[health_questions[current_question]] = response\n",
    "    else:\n",
    "        responses[\"User\"] = response\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "def update_question():\n",
    "    if current_question == -1:  # Name entry stage\n",
    "        question.config(text=\"Please enter your name:\")\n",
    "    elif current_question < len(health_questions):\n",
    "        question.config(text=f\"{current_question + 1}. {health_questions[current_question]}\")\n",
    "    else:\n",
    "        responses_df = pd.DataFrame([responses])  # Convert dict to DataFrame\n",
    "        if os.path.isfile('responses.csv'):     # If file exists, append without writing headers\n",
    "            responses_df.to_csv('responses.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            responses_df.to_csv(\"responses.csv\", index=False)\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        root.destroy()\n",
    "\n",
    "def go_back():\n",
    "    global current_question\n",
    "    if current_question > 0:\n",
    "        current_question -= 1\n",
    "        responses.pop(health_questions[current_question])\n",
    "        update_question()\n",
    "\n",
    "def begin_survey():\n",
    "    global current_question\n",
    "    responses[\"User\"] = entry.get()\n",
    "    entry.pack_forget()\n",
    "    begin_button.pack_forget()\n",
    "    yes_button.pack()\n",
    "    no_button.pack()\n",
    "    back_button.pack()\n",
    "    skip_button.pack()\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "question = tk.Label(root, text=\"Please enter your name:\")\n",
    "question.pack()\n",
    "\n",
    "entry = tk.Entry(root)\n",
    "entry.pack()\n",
    "\n",
    "begin_button = tk.Button(root, text=\"Begin\", command=begin_survey)\n",
    "begin_button.pack()\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"))\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"))\n",
    "back_button = tk.Button(root, text=\"Back\", command=go_back)\n",
    "skip_button = tk.Button(root, text=\"Skip\", command=lambda: record_response(\"skip\"))\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a415723",
   "metadata": {},
   "source": [
    "### Adding Numerical Variables to the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc96c8a1",
   "metadata": {},
   "source": [
    "Some variables, such as demographic information, could not be easily incorporated into buttons. So, I added additonal entries to the Tkinter window that would allow them to enter such info. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8a656b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "health_questions = [\n",
    "    \"Have you had any headaches in the past week?\",\n",
    "    \"Have you been exercising regularly?\",\n",
    "    \"Are you currently on any form of medication?\",\n",
    "    # Add more questions as needed.\n",
    "]\n",
    "\n",
    "current_question = -1\n",
    "responses = {}\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question\n",
    "    if current_question >= 0:  # Skip if still on question stage\n",
    "        responses[health_questions[current_question]] = response\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "def update_question():\n",
    "    if current_question == -1:  # Information entry stage\n",
    "        question.config(text=\"Please enter your details:\")\n",
    "    elif current_question < len(health_questions):\n",
    "        question.config(text=f\"{current_question + 1}. {health_questions[current_question]}\")\n",
    "    else:\n",
    "        responses_df = pd.DataFrame([responses])  # Convert dict to DataFrame\n",
    "        if os.path.isfile('responses.csv'):     # If file exists, append without writing headers\n",
    "            responses_df.to_csv('responses.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            responses_df.to_csv(\"responses.csv\", index=False)  # Write headers if file does not exist\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        root.destroy()\n",
    "\n",
    "def go_back():\n",
    "    global current_question\n",
    "    if current_question > 0:\n",
    "        current_question -= 1\n",
    "        responses.pop(health_questions[current_question])\n",
    "        update_question()\n",
    "\n",
    "def begin_survey():\n",
    "    global current_question\n",
    "    responses[\"User\"] = name_entry.get()\n",
    "    responses[\"Age\"] = age_entry.get()\n",
    "    responses[\"Weight\"] = weight_entry.get()\n",
    "    responses[\"Height\"] = height_entry.get()\n",
    "    entry_frame.pack_forget()\n",
    "    begin_button.pack_forget()\n",
    "    yes_button.pack()\n",
    "    no_button.pack()\n",
    "    back_button.pack()\n",
    "    skip_button.pack()\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "question = tk.Label(root, text=\"Please enter your details:\")\n",
    "question.pack()\n",
    "\n",
    "entry_frame = tk.Frame(root)\n",
    "entry_frame.pack()\n",
    "\n",
    "name_label = tk.Label(entry_frame, text=\"Name:\")\n",
    "name_label.pack(side=\"left\")\n",
    "name_entry = tk.Entry(entry_frame)\n",
    "name_entry.pack(side=\"left\")\n",
    "\n",
    "age_label = tk.Label(entry_frame, text=\"Age:\")\n",
    "age_label.pack(side=\"left\")\n",
    "age_entry = tk.Entry(entry_frame)\n",
    "age_entry.pack(side=\"left\")\n",
    "\n",
    "weight_label = tk.Label(entry_frame, text=\"Weight (kg):\")\n",
    "weight_label.pack(side=\"left\")\n",
    "weight_entry = tk.Entry(entry_frame)\n",
    "weight_entry.pack(side=\"left\")\n",
    "\n",
    "height_label = tk.Label(entry_frame, text=\"Height (cm):\")\n",
    "height_label.pack(side=\"left\")\n",
    "height_entry = tk.Entry(entry_frame)\n",
    "height_entry.pack(side=\"left\")\n",
    "\n",
    "begin_button = tk.Button(root, text=\"Begin\", command=begin_survey)\n",
    "begin_button.pack()\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"))\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"))\n",
    "back_button = tk.Button(root, text=\"Back\", command=go_back)\n",
    "skip_button = tk.Button(root, text=\"Skip\", command=lambda: record_response(\"skip\"))\n",
    "\n",
    "total_questions = tk.Label(root, text=f\"Total questions: {len(health_questions)}\")\n",
    "total_questions.pack()\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3d54e",
   "metadata": {},
   "source": [
    "### Adding More Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c280395",
   "metadata": {},
   "source": [
    "I then asked ChatGPT, to include some extra questions to flesh out the survey. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3e2d6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "health_questions = [\n",
    "    \"Have you had any headaches in the past week?\",\n",
    "    \"Have you been exercising regularly?\",\n",
    "    \"Are you currently on any form of medication?\",\n",
    "    \"Do you usually sleep for at least 7-8 hours a night?\",\n",
    "    \"Have you experienced any sudden weight changes in the past month?\",\n",
    "    \"Have you been feeling more stressed than usual in the past month?\",\n",
    "    \"Do you usually consume at least 5 servings of fruits and vegetables per day?\",\n",
    "    \"Have you felt depressed or hopeless in the last two weeks?\",\n",
    "    \"Do you experience regular physical activity (e.g., walking, jogging, cycling) at least 3 times a week?\",\n",
    "    \"Have you experienced any unexplained aches or pains in the past month?\"\n",
    "]\n",
    "\n",
    "current_question = -1\n",
    "responses = {}\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question\n",
    "    if current_question >= 0:  # Skip if still on question stage\n",
    "        responses[health_questions[current_question]] = response\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "def update_question():\n",
    "    if current_question == -1:  # Information entry stage\n",
    "        question.config(text=\"Please enter your details:\")\n",
    "    elif current_question < len(health_questions):\n",
    "        question.config(text=f\"{current_question + 1}. {health_questions[current_question]}\")\n",
    "    else:\n",
    "        responses_df = pd.DataFrame([responses])  # Convert dict to DataFrame\n",
    "        if os.path.isfile('responses.csv'):     # If file exists, append without writing headers\n",
    "            responses_df.to_csv('responses.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            responses_df.to_csv(\"responses.csv\", index=False)  # Write headers if file does not exist\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        root.destroy()\n",
    "\n",
    "def go_back():\n",
    "    global current_question\n",
    "    if current_question > 0:\n",
    "        current_question -= 1\n",
    "        responses.pop(health_questions[current_question])\n",
    "        update_question()\n",
    "\n",
    "def begin_survey():\n",
    "    global current_question\n",
    "    responses[\"User\"] = name_entry.get()\n",
    "    responses[\"Age\"] = age_entry.get()\n",
    "    responses[\"Weight\"] = weight_entry.get()\n",
    "    responses[\"Height\"] = height_entry.get()\n",
    "    entry_frame.pack_forget()\n",
    "    begin_button.pack_forget()\n",
    "    yes_button.pack()\n",
    "    no_button.pack()\n",
    "    back_button.pack()\n",
    "    skip_button.pack()\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "question = tk.Label(root, text=\"Please enter your details:\")\n",
    "question.pack()\n",
    "\n",
    "entry_frame = tk.Frame(root)\n",
    "entry_frame.pack()\n",
    "\n",
    "name_label = tk.Label(entry_frame, text=\"Name:\")\n",
    "name_label.pack(side=\"left\")\n",
    "name_entry = tk.Entry(entry_frame)\n",
    "name_entry.pack(side=\"left\")\n",
    "\n",
    "age_label = tk.Label(entry_frame, text=\"Age:\")\n",
    "age_label.pack(side=\"left\")\n",
    "age_entry = tk.Entry(entry_frame)\n",
    "age_entry.pack(side=\"left\")\n",
    "\n",
    "weight_label = tk.Label(entry_frame, text=\"Weight (kg):\")\n",
    "weight_label.pack(side=\"left\")\n",
    "weight_entry = tk.Entry(entry_frame)\n",
    "weight_entry.pack(side=\"left\")\n",
    "\n",
    "height_label = tk.Label(entry_frame, text=\"Height (cm):\")\n",
    "height_label.pack(side=\"left\")\n",
    "height_entry = tk.Entry(entry_frame)\n",
    "height_entry.pack(side=\"left\")\n",
    "\n",
    "begin_button = tk.Button(root, text=\"Begin\", command=begin_survey)\n",
    "begin_button.pack()\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"))\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"))\n",
    "back_button = tk.Button(root, text=\"Back\", command=go_back)\n",
    "skip_button = tk.Button(root, text=\"Skip\", command=lambda: record_response(\"skip\"))\n",
    "\n",
    "total_questions = tk.Label(root, text=f\"Total questions: {len(health_questions)}\")\n",
    "total_questions.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20634cd3",
   "metadata": {},
   "source": [
    "### Adding Follow-Up Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff064c2c",
   "metadata": {},
   "source": [
    "I wanted there to be follow up questions to the survey that were dependent on earlier answers. This was difficult to get the prompt to accomplish effectively, but after some trail and error, I was successful. Here is the resulting code with follow-up questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a07079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "questions = [\n",
    "    [\"Have you had any headaches in the past week?\", [\"How many times did headaches occur in the past week?\", [\"1-2 times\", \"3-5 times\", \"More than 5 times\"]]],\n",
    "    [\"Have you been exercising regularly?\", [\"How many times a week do you exercise?\", [\"1-2 times\", \"3-5 times\", \"More than 5 times\"]]],\n",
    "    [\"Are you currently on any form of medication?\", None],\n",
    "    # ... add more questions as needed\n",
    "]\n",
    "\n",
    "current_question = -1\n",
    "follow_up = False\n",
    "responses = {}\n",
    "follow_up_buttons = []\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question, follow_up, follow_up_buttons\n",
    "    if follow_up:  # If in follow-up stage\n",
    "        responses[questions[current_question][1][0]] = response\n",
    "        follow_up = False\n",
    "        for button in follow_up_buttons:  # Destroy follow-up buttons\n",
    "            button.destroy()\n",
    "        follow_up_buttons = []\n",
    "    else:\n",
    "        responses[questions[current_question][0]] = response\n",
    "        if questions[current_question][1]:  # If there's a follow-up question\n",
    "            follow_up = True\n",
    "            for option in questions[current_question][1][1]:\n",
    "                button = tk.Button(root, text=option, command=lambda option=option: record_response(option))\n",
    "                button.pack()\n",
    "                follow_up_buttons.append(button)\n",
    "            return\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "def update_question():\n",
    "    if current_question < len(questions):\n",
    "        question.config(text=f\"{current_question + 1}. {questions[current_question][0]}\")\n",
    "    else:\n",
    "        responses_df = pd.DataFrame([responses])  # Convert dict to DataFrame\n",
    "        responses_df = responses_df.replace(\"\", np.nan)  # Replace empty strings with NaN\n",
    "        if os.path.isfile('responses.csv'):     # If file exists, append without writing headers\n",
    "            responses_df.to_csv('responses.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            responses_df.to_csv(\"responses.csv\", index=False)  # Write headers if file does not exist\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        root.destroy()\n",
    "\n",
    "def begin_survey():\n",
    "    global current_question\n",
    "    responses[\"User\"] = name_entry.get()\n",
    "    responses[\"Age\"] = age_entry.get()\n",
    "    responses[\"Weight\"] = weight_entry.get()\n",
    "    responses[\"Height\"] = height_entry.get()\n",
    "    entry_frame.pack_forget()\n",
    "    begin_button.pack_forget()\n",
    "    yes_button.pack()\n",
    "    no_button.pack()\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "question = tk.Label(root, text=\"Please enter your details:\")\n",
    "question.pack()\n",
    "\n",
    "entry_frame = tk.Frame(root)\n",
    "entry_frame.pack()\n",
    "\n",
    "name_label = tk.Label(entry_frame, text=\"Name:\")\n",
    "name_label.pack(side=\"left\")\n",
    "name_entry = tk.Entry(entry_frame)\n",
    "name_entry.pack(side=\"left\")\n",
    "\n",
    "age_label = tk.Label(entry_frame, text=\"Age:\")\n",
    "age_label.pack(side=\"left\")\n",
    "age_entry = tk.Entry(entry_frame)\n",
    "age_entry.pack(side=\"left\")\n",
    "\n",
    "weight_label = tk.Label(entry_frame, text=\"Weight (kg):\")\n",
    "weight_label.pack(side=\"left\")\n",
    "weight_entry = tk.Entry(entry_frame)\n",
    "weight_entry.pack(side=\"left\")\n",
    "\n",
    "height_label = tk.Label(entry_frame, text=\"Height (cm):\")\n",
    "height_label.pack(side=\"left\")\n",
    "height_entry = tk.Entry(entry_frame)\n",
    "height_entry.pack(side=\"left\")\n",
    "\n",
    "begin_button = tk.Button(root, text=\"Begin\", command=begin_survey)\n",
    "begin_button.pack()\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"))\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"))\n",
    "\n",
    "total_questions = tk.Label(root, text=f\"Total questions: {len(questions)}\")\n",
    "total_questions.pack()\n",
    "\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eaa341",
   "metadata": {},
   "source": [
    "# Finalizing the MVP UI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5abc560f",
   "metadata": {},
   "source": [
    "Finally, after the script is has been shown to work, it is time to format the user interface. To do this, I changed the background color to pink, made the text wrap, and had the entries for the starting variables appear on different lines. This was the first code block that I had to modify myself throughout this project. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de96c0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import messagebox\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "questions = [\n",
    "    [\"Have you had any headaches in the past week?\", [\"How many times did headaches occur in the past week?\", [\"1-2 times\", \"3-5 times\", \"More than 5 times\"]]],\n",
    "    [\"Have you been exercising regularly?\", [\"How many times a week do you exercise?\", [\"1-2 times\", \"3-5 times\", \"More than 5 times\"]]],\n",
    "    [\"Are you currently on any form of medication?\", None],\n",
    "    [\"Do you usually sleep for at least 7-8 hours a night?\", None],\n",
    "    [\"Have you experienced any sudden weight changes in the past month?\", None],\n",
    "    [\"Have you been feeling more stressed than usual in the past month?\",[\"How often do you feel stressed?\",[\"Often\",\"Sometimes\"]]],\n",
    "    [\"Do you usually consume at least 5 servings of fruits and vegetables per day?\", None],\n",
    "    [\"Have you felt depressed or hopeless in the last two weeks?\", [\"How severe is your stress\",[\"Very\",\"Intermediate\",\"Mild\"]]],\n",
    "    [\"Have you experienced any unexplained aches or pains in the past month?\", None]\n",
    "]\n",
    "\n",
    "current_question = -1\n",
    "follow_up = False\n",
    "responses = {}\n",
    "follow_up_buttons = []\n",
    "\n",
    "def record_response(response):\n",
    "    global current_question, follow_up, follow_up_buttons\n",
    "    if follow_up:  # If in follow-up stage\n",
    "        responses[questions[current_question][1][0]] = response\n",
    "        follow_up = False\n",
    "        for button in follow_up_buttons:  # Destroy follow-up buttons\n",
    "            button.destroy()\n",
    "        follow_up_buttons = []\n",
    "    else:\n",
    "        responses[questions[current_question][0]] = response\n",
    "        if questions[current_question][1]:  # If there's a follow-up question\n",
    "            follow_up = True\n",
    "            for option in questions[current_question][1][1]:\n",
    "                button = tk.Button(root, text=option, command=lambda option=option: record_response(option), width=30, wraplength=150)\n",
    "                button.pack()\n",
    "                follow_up_buttons.append(button)\n",
    "            return\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "def update_question():\n",
    "    if current_question < len(questions):\n",
    "        question.config(text=f\"{current_question + 1}. {questions[current_question][0]}\")\n",
    "    else:\n",
    "        responses_df = pd.DataFrame([responses])  # Convert dict to DataFrame\n",
    "        responses_df = responses_df.replace(\"\", np.nan)  # Replace empty strings with NaN\n",
    "        if os.path.isfile('responses.csv'):     # If file exists, append without writing headers\n",
    "            responses_df.to_csv('responses.csv', mode='a', header=False, index=False)\n",
    "        else:\n",
    "            responses_df.to_csv(\"responses.csv\", index=False)  # Write headers if file does not exist\n",
    "        messagebox.showinfo(\"Done\", \"Thank you for your responses. They will be used for important research.\")\n",
    "        root.destroy()\n",
    "\n",
    "def begin_survey():\n",
    "    global current_question\n",
    "    responses[\"User\"] = name_entry.get()\n",
    "    responses[\"Age\"] = age_entry.get()\n",
    "    responses[\"Weight\"] = weight_entry.get()\n",
    "    responses[\"Height\"] = height_entry.get()\n",
    "    entry_frame.pack_forget()\n",
    "    begin_button.pack_forget()\n",
    "    yes_button.pack()\n",
    "    no_button.pack()\n",
    "    current_question += 1\n",
    "    update_question()\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "# Set window size as an average phone size (in pixels)\n",
    "root.geometry('375x667')\n",
    "root.configure(bg='pink')\n",
    "\n",
    "title = tk.Label(root, text=\"Wom.A.N.N. MVP\", font=('Helvetica', 16, 'bold'), bg='pink')\n",
    "title.pack(pady=20)\n",
    "\n",
    "question = tk.Label(root, text=\"Please enter your details:\", font=('Helvetica', 14), wraplength=300, justify=\"left\", bg='pink')\n",
    "question.pack()\n",
    "\n",
    "entry_frame = tk.Frame(root, bg='pink')\n",
    "entry_frame.pack()\n",
    "\n",
    "name_label = tk.Label(entry_frame, text=\"Name:\", font=('Helvetica', 12), bg='pink')\n",
    "name_label.pack()\n",
    "name_entry = tk.Entry(entry_frame, font=('Helvetica', 12))\n",
    "name_entry.pack()\n",
    "\n",
    "age_label = tk.Label(entry_frame, text=\"Age:\", font=('Helvetica', 12), bg='pink')\n",
    "age_label.pack()\n",
    "age_entry = tk.Entry(entry_frame, font=('Helvetica', 12))\n",
    "age_entry.pack()\n",
    "\n",
    "weight_label = tk.Label(entry_frame, text=\"Weight (kg):\", font=('Helvetica', 12), bg='pink')\n",
    "weight_label.pack()\n",
    "weight_entry = tk.Entry(entry_frame, font=('Helvetica', 12))\n",
    "weight_entry.pack()\n",
    "\n",
    "height_label = tk.Label(entry_frame, text=\"Height (cm):\", font=('Helvetica', 12), bg='pink')\n",
    "height_label.pack()\n",
    "height_entry = tk.Entry(entry_frame, font=('Helvetica', 12))\n",
    "height_entry.pack()\n",
    "\n",
    "begin_button = tk.Button(root, text=\"Begin\", command=begin_survey, font=('Helvetica', 12))\n",
    "begin_button.pack(pady=10)\n",
    "\n",
    "yes_button = tk.Button(root, text=\"Yes\", command=lambda: record_response(\"yes\"), font=('Helvetica', 12), width=30, wraplength=150)\n",
    "no_button = tk.Button(root, text=\"No\", command=lambda: record_response(\"no\"), font=('Helvetica', 12), width=30, wraplength=150)\n",
    "\n",
    "total_questions = tk.Label(root, text=f\"Total questions: {len(questions)}\", font=('Helvetica', 12), bg='pink')\n",
    "total_questions.pack(pady=20)\n",
    "\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d97aeea",
   "metadata": {},
   "source": [
    "### Creating a neural network that can work with the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a9bd6c6",
   "metadata": {},
   "source": [
    "I then tried to quickly create a neural network that could be trained on the data I was generating. There is an error with this code because it is not set to work off of an exisiting column name. I do not think it was wise to use the questions that are included in the MVP to diagnose depression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6f5a4fbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'depression_level'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3_1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'depression_level'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-2a3a1837303f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Assume 'depression_level' is your target variable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'depression_level'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'depression_level'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_1\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3023\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3024\u001b[1;33m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3025\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3026\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3_1\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3080\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3081\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3082\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3083\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3084\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtolerance\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'depression_level'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"responses.csv\")\n",
    "\n",
    "# Assume 'depression_level' is your target variable\n",
    "target = df['depression_level']\n",
    "data = df.drop('depression_level', axis=1)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a custom PyTorch dataset\n",
    "class DepressionDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]\n",
    "\n",
    "# Create dataloaders\n",
    "batch_size = 64\n",
    "train_dataset = DepressionDataset(X_train, y_train)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataset = DepressionDataset(X_test, y_test)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define the neural network\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(X_train.shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)\n",
    "\n",
    "# Initialize the model, loss function and optimizer\n",
    "model = NeuralNetwork()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "# Training loop\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    for X, y in train_dataloader:\n",
    "        X, y = X.float(), y.float()\n",
    "        \n",
    "        # Forward pass\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch+1}, Loss: {loss.item()}\")\n",
    "\n",
    "# Evaluate on test data\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.float(), y.float()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "    print(f\"Test Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1b6b2",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f491b8",
   "metadata": {},
   "source": [
    "[1] https://www.cnn.com/2022/09/21/health/global-womens-health-index-2021/index.html <br>\n",
    "[2] https://www.mckinsey.com/industries/life-sciences/our-insights/closing-the-data-gaps-in-womens-health <br>\n",
    "[3] https://www.nature.com/immersive/d41586-023-01475-2/index.html <br>\n",
    "[4] https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7830703/ <br>\n",
    "[5] https://bmcpublichealth.biomedcentral.com/articles/10.1186/s12889-016-3352-y <br>\n",
    "[6] https://www.nature.com/articles/d41586-023-01472-5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
